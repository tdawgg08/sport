from aiogram import Router, F, types
from aiogram.enums import ParseMode
from aiogram.filters import StateFilter
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from database.models import User
from keyboards.gpt import gpt_kb

import requests
import json
from dotenv import load_dotenv
import os

load_dotenv()

router = Router()

API_KEY = os.getenv('API_KEY_GPT')
MODEL = 'deepseek/deepseek-r1'


async def send_recomendation(user_id, message : types.Message):
    data = await User.filter(telegram_id=user_id)
    values = {
        '1-1': data[0].first_answer,
        '1-2': data[0].second_answer,
        '1-3': data[0].third_answer,
        '1-4': data[0].fourth_answer,
        '2-1': data[0].fifth_answer,
        '2-2': data[0].sixth_answer,
        '2-3': data[0].seventh_answer,
    }

    prompt = '''–¢—ã - –æ–ø—ã—Ç–Ω—ã–π –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–µ—Ä –∏ –¥–∏–µ—Ç–æ–ª–æ–≥. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ—Ç–≤–µ—Ç—ã –∫–ª–∏–µ–Ω—Ç–∞ –∏–∑ –∞–Ω–∫–µ—Ç—ã –∏ —Å–æ—Å—Ç–∞–≤—å –ü–ï–†–°–û–ù–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –ø–ª–∞–Ω —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π.

–î–ê–ù–ù–´–ï –ò–ó –ê–ù–ö–ï–¢–´ –ö–õ–ò–ï–ù–¢–ê:
{data}

–ò–ù–°–¢–†–£–ö–¶–ò–Ø –î–õ–Ø –¢–ï–ë–Ø:
1. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ü–∏—Ñ—Ä–æ–≤—ã–µ –æ—Ç–≤–µ—Ç—ã –∫–∞–∫ —É—Ä–æ–≤–Ω–∏/–±–∞–ª–ª—ã (1-–Ω–∏–∑–∫–∏–π, 3-—Å—Ä–µ–¥–Ω–∏–π, 5-–≤—ã—Å–æ–∫–∏–π)
2. –î–∞–π –ö–û–ù–ö–†–ï–¢–ù–´–ï —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –±–µ–∑ –æ–±—â–∏—Ö —Ñ—Ä–∞–∑
3. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –æ—Ç–≤–µ—Ç —á–µ—Ç–∫–æ –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º
4. –ü—Ä–µ–¥–ª–∞–≥–∞–π —Ä–µ–∞–ª—å–Ω–æ –≤—ã–ø–æ–ª–Ω–∏–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
5. –£—á–∏—Ç—ã–≤–∞–π –≤–∑–∞–∏–º–æ—Å–≤—è–∑—å –º–µ–∂–¥—É –æ—Ç–≤–µ—Ç–∞–º–∏

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (—Å–æ–±–ª—é–¥–∞–π —Ç–æ—á–Ω–æ):

üèãÔ∏è –ü–ï–†–°–û–ù–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –ü–õ–ê–ù –¢–†–ï–ù–ò–†–û–í–û–ö

üìÖ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è —á–∞—Å—Ç–æ—Ç–∞: [—É–∫–∞–∂–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ]
üí™ –û—Å–Ω–æ–≤–Ω—ã–µ –∞–∫—Ü–µ–Ω—Ç—ã: [–Ω–∞ —á—Ç–æ –¥–µ–ª–∞—Ç—å —É–ø–æ—Ä]
‚ö° –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å: [—É—Ä–æ–≤–µ–Ω—å –Ω–∞–≥—Ä—É–∑–∫–∏]

–¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–Ω–∏:
‚Ä¢ –î–µ–Ω—å 1: [–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è, –ø–æ–¥—Ö–æ–¥—ã, –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è]
‚Ä¢ –î–µ–Ω—å 2: [–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è, –ø–æ–¥—Ö–æ–¥—ã, –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è]
‚Ä¢ –î–µ–Ω—å 3: [–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è, –ø–æ–¥—Ö–æ–¥—ã, –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è]

ü•ó –ü–õ–ê–ù –ü–ò–¢–ê–ù–ò–Ø –ò –†–ï–ñ–ò–ú

üçΩÔ∏è –†–µ–∂–∏–º –ø–∏—Ç–∞–Ω–∏—è: [—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø–∏—Ç–∞–Ω–∏—é]
üìä –ö–∞–ª–æ—Ä–∏–π–Ω–æ—Å—Ç—å: [–æ—Ä–∏–µ–Ω—Ç–∏—Ä—ã]
ü•õ –ì–∏–¥—Ä–∞—Ç–∞—Ü–∏—è: [—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤–æ–¥–µ]
‚è∞ –†–µ–∂–∏–º –¥–Ω—è: [—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ]

üîÑ –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ò–ï –ò –ü–†–û–ì–†–ï–°–°

üí§ –°–æ–Ω: [—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏]
üìà –ö–æ–Ω—Ç—Ä–æ–ª—å –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: [–∫–∞–∫ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å]
‚ö° –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏: [–∫–æ–≥–¥–∞ –≤–Ω–æ—Å–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è]

üéØ –ö–õ–Æ–ß–ï–í–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò
‚Ä¢ [3-4 —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö –ø—É–Ω–∫—Ç–∞]

–ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã, –¥–∞–≤–∞–π —Ç–æ–ª—å–∫–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ —Ü–∏—Ñ—Ä–∞—Ö –∏–∑ –∞–Ω–∫–µ—Ç—ã.'''

    data_str = ""
    for key, value in values.items():
        question_number, answer_number = key.split('-')
        data_str += f'–†–∞–∑–¥–µ–ª {question_number}, –≤–æ–ø—Ä–æ—Å {answer_number}: {value}\n'

    prompt = prompt.format(data=data_str)
    
    headers = {
        'Authorization': f'Bearer {API_KEY}',
        'Content-Type': 'application/json'
    }

    data = {
        'model': MODEL,
        'messages': [{'role': 'user', 'content': prompt}],
        'stream': True
    }

    bot_message = await message.answer("üîç –ù–µ–π—Ä–æ—Å–µ—Ç—å –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç...")
    full_response = []

    try:
        with requests.post(
            'https://openrouter.ai/api/v1/chat/completions',
            headers=headers,
            json=data,
            stream=True
        ) as response:
            if response.status_code != 200:
                await bot_message.edit_text("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏")
                return
            
            for chunk in response.iter_lines():
                if chunk:
                    chunk_str = chunk.decode('utf-8').replace('data:', '')
                    try:
                        chunk_json = json.loads(chunk_str)
                        if 'choices' in chunk_json:
                            content = chunk_json['choices'][0]['delta'].get('content', '')
                            if content:
                                cleaned = process_content(content)
                                full_response.append(cleaned)
                                if len(full_response) % 5 == 0: 
                                    await bot_message.edit_text(
                                        f"ü§ñ –û—Ç–≤–µ—Ç:\n\n{''.join(full_response)}",
                                        parse_mode=ParseMode.MARKDOWN
                                    )
                    except:
                        pass
            
            if full_response:
                await bot_message.edit_text(
                    f"ü§ñ –û—Ç–≤–µ—Ç:\n\n{''.join(full_response)}",
                    parse_mode=ParseMode.MARKDOWN,
                    reply_markup=gpt_kb()
                )
            else:
                await bot_message.edit_text("‚ùå –ù–µ–π—Ä–æ—Å–µ—Ç—å –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ –æ—Ç–≤–µ—Ç")
                
    except Exception as e:
        await bot_message.edit_text(f"‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}")


def process_content(content):
    return content.replace('<think>', '').replace('</think>', '')

